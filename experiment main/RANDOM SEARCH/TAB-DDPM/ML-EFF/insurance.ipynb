{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12100095,"sourceType":"datasetVersion","datasetId":7617668}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sdv synthcity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:18:41.951837Z","iopub.execute_input":"2025-06-08T23:18:41.952157Z","iopub.status.idle":"2025-06-08T23:22:53.156355Z","shell.execute_reply.started":"2025-06-08T23:18:41.952133Z","shell.execute_reply":"2025-06-08T23:22:53.155212Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"VPRsmnAsaomm","outputId":"bf56ebda-90ea-4c3f-f272-edac3a27e682"},"outputs":[{"name":"stdout","text":"Collecting sdv\n  Downloading sdv-1.22.1-py3-none-any.whl.metadata (14 kB)\nCollecting synthcity\n  Downloading synthcity-0.2.12-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: boto3<2.0.0,>=1.28 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.38.11)\nRequirement already satisfied: botocore<2.0.0,>=1.31 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.38.11)\nRequirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (3.1.1)\nRequirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.3)\nRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.26.4)\nRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.3)\nRequirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\nCollecting copulas>=0.12.1 (from sdv)\n  Downloading copulas-0.12.2-py3-none-any.whl.metadata (9.4 kB)\nCollecting ctgan>=0.11.0 (from sdv)\n  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\nCollecting deepecho>=0.7.0 (from sdv)\n  Downloading deepecho-0.7.0-py3-none-any.whl.metadata (10 kB)\nCollecting rdt>=1.17.0 (from sdv)\n  Downloading rdt-1.17.0-py3-none-any.whl.metadata (10 kB)\nCollecting sdmetrics>=0.21.0 (from sdv)\n  Downloading sdmetrics-0.21.0-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.3.8)\nRequirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (6.0.2)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity) (8.7.0)\nCollecting torch<2.3,>=2.1 (from synthcity)\n  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.2.2)\nCollecting nflows>=0.14 (from synthcity)\n  Downloading nflows-0.14.tar.gz (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting lifelines<0.30.0,>=0.29.0 (from synthcity)\n  Downloading lifelines-0.29.0-py3-none-any.whl.metadata (3.2 kB)\nCollecting opacus>=1.3 (from synthcity)\n  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\nCollecting networkx<3.0,>2.0 (from synthcity)\n  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\nCollecting decaf-synthetic-data>=0.1.6 (from synthcity)\n  Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from synthcity) (4.3.0)\nRequirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity) (0.44.1)\nRequirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity) (9.1.2)\nCollecting loguru (from synthcity)\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.11.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.15.2)\nRequirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.0.3)\nCollecting geomloss (from synthcity)\n  Downloading geomloss-0.2.6.tar.gz (26 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pgmpy<1.0 (from synthcity)\n  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\nCollecting redis (from synthcity)\n  Downloading redis-6.2.0-py3-none-any.whl.metadata (10 kB)\nCollecting pycox (from synthcity)\n  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting xgbse>=0.3.1 (from synthcity)\n  Downloading xgbse-0.3.3-py3-none-any.whl.metadata (17 kB)\nCollecting pykeops (from synthcity)\n  Downloading pykeops-2.3.tar.gz (552 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting fflows (from synthcity)\n  Downloading fflows-0.0.3-py3-none-any.whl.metadata (3.4 kB)\nCollecting monai (from synthcity)\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nCollecting tsai (from synthcity)\n  Downloading tsai-0.4.0-py3-none-any.whl.metadata (16 kB)\nCollecting be-great>=0.0.5 (from synthcity)\n  Downloading be_great-0.0.9-py3-none-any.whl.metadata (5.8 kB)\nCollecting arfpy (from synthcity)\n  Downloading arfpy-0.1.1.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: fastcore<1.8 in /usr/local/lib/python3.11/dist-packages (from synthcity) (1.7.29)\nRequirement already satisfied: fastai<2.8 in /usr/local/lib/python3.11/dist-packages (from synthcity) (2.7.19)\nRequirement already satisfied: datasets>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (3.6.0)\nRequirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (4.51.3)\nRequirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity) (1.5.2)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (1.0.1)\nRequirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (0.12.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.9.0.post0)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.4.0)\nRequirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\nCollecting pytorch-lightning<2.0 (from decaf-synthetic-data>=0.1.6->synthcity)\n  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\nCollecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (25.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (0.0.7)\nRequirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (0.21.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (3.7.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (2.32.3)\nRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (11.1.0)\nRequirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity) (3.8.5)\nRequirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity) (1.7.0)\nCollecting autograd-gamma>=0.3 (from lifelines<0.30.0,>=0.29.0->synthcity)\n  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting formulaic>=0.2.2 (from lifelines<0.30.0,>=0.29.0->synthcity)\n  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity) (2.18.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->sdv) (2.4.1)\nRequirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity) (3.4.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (6.9.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity) (2.0.40)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (3.0.9)\nRequirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (0.14.4)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (1.5.0)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity) (0.8.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity) (0.4.0)\nCollecting Faker>=17 (from rdt>=1.17.0->sdv)\n  Downloading faker-37.3.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.18.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (1.13.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch<2.3,>=2.1->synthcity)\n  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity) (12.9.41)\nCollecting scikit-learn>=1.2 (from synthcity)\n  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\nCollecting xgboost<3.0.0 (from synthcity)\n  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity) (3.21.0)\nCollecting torchtuples>=0.2.0 (from pycox->synthcity)\n  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\nCollecting feather-format>=0.4.0 (from pycox->synthcity)\n  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (3.13.0)\nRequirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity) (0.60.0)\nCollecting py7zr>=0.11.3 (from pycox->synthcity)\n  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from pykeops->synthcity) (2.13.6)\nCollecting keopscore==2.3 (from pykeops->synthcity)\n  Downloading keopscore-2.3.tar.gz (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity) (0.0.7)\nCollecting pyts>=0.13.0 (from tsai->synthcity)\n  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (0.13.0)\nRequirement already satisfied: psutil>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity) (7.0.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity) (0.5.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity) (1.3.10)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.70.16)\nCollecting fsspec (from torch<2.3,>=2.1->synthcity)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity)\n  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity) (1.17.2)\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity) (0.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity) (1.4.8)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity) (0.43.0)\nRequirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity) (3.22.0)\nCollecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting pyzstd>=0.16.1 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting pyppmd<1.3.0,>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity)\n  Downloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity) (1.7.1)\nRequirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity) (0.14.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity) (2025.4.26)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (0.15.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (75.2.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity) (3.5.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity) (3.1.1)\nINFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\nCollecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity)\n  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision>=0.11 (from fastai<2.8->synthcity)\n  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\nINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity) (0.21.1)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (2.164.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (2.40.1)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity) (3.20.3)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity) (1.26.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->sdv) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->sdv) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.0->sdv) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.0->sdv) (2024.2.0)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy<1.0->synthcity) (1.0.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity) (1.3.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (1.72.0rc1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity) (3.1.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (3.11.18)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai->pgmpy<1.0->synthcity) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (4.9.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.1->be-great>=0.0.5->synthcity) (1.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.0->sdv) (2024.2.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity) (1.3.0)\nCollecting scikit-learn>=1.2 (from synthcity)\n  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity) (1.2.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity) (0.21.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity) (7.1.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity) (4.1.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity) (1.20.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity) (1.49.0rc1)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity) (1.2.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity) (0.6.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity) (0.1.2)\nDownloading sdv-1.22.1-py3-none-any.whl (180 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading synthcity-0.2.12-py3-none-any.whl (434 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading be_great-0.0.9-py3-none-any.whl (19 kB)\nDownloading copulas-0.12.2-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ctgan-0.11.0-py3-none-any.whl (24 kB)\nDownloading decaf_synthetic_data-0.1.6-py3-none-any.whl (9.1 kB)\nDownloading deepecho-0.7.0-py3-none-any.whl (27 kB)\nDownloading lifelines-0.29.0-py3-none-any.whl (349 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading opacus-1.5.4-py3-none-any.whl (254 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rdt-1.17.0-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sdmetrics-0.21.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\nDownloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fflows-0.0.3-py3-none-any.whl (19 kB)\nDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading redis-6.2.0-py3-none-any.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faker-37.3.0-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\nDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=95568231795262e6443276eeea7136173ff73f1fcf3edc0372ee212ec4a0d7b8\n  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=50627b32fc295b8d674706e8d27208544f5618898d8cf93202a17046a3789042\n  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=34ddd0ca172d921e284a2d476192474d7853bad5cce2704d152cf745a1d828f9\n  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=d99aa3e1b27c11fdcc1483781170171b553eb59d52c6bdd806e05a9f187f2f6a\n  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=07d3c1328299979ec5ac906518542d3a8750e814a7a11bce7eaad94085ee8246\n  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=e74f194b84fdf62bbd7b2fdf33313ba4a23ad2186b9e7396e974529a6975f916\n  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=505b8dc3ed88303a2ee9ac61d1b2112a0fb193c8c2303064cc69092c31a157c8\n  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\nSuccessfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\nInstalling collected packages: brotli, triton, redis, pyzstd, pyppmd, pybcj, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multivolumefile, loguru, keopscore, interface-meta, inflate64, fsspec, feather-format, Faker, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, scikit-learn, torchvision, formulaic, autograd-gamma, xgboost, torchtuples, torchtext, rdt, pyts, pytorch-lightning, lifelines, copulas, xgbse, tsai, sdmetrics, pykeops, pycox, pgmpy, opacus, nflows, monai, geomloss, fflows, deepecho, decaf-synthetic-data, ctgan, be-great, arfpy, synthcity, sdv\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.4.2\n    Uninstalling networkx-3.4.2:\n      Successfully uninstalled networkx-3.4.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.0.3\n    Uninstalling xgboost-2.0.3:\n      Successfully uninstalled xgboost-2.0.3\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.5.1.post0\n    Uninstalling pytorch-lightning-2.5.1.post0:\n      Successfully uninstalled pytorch-lightning-2.5.1.post0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Faker-37.3.0 arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.9 brotli-1.1.0 copulas-0.12.2 ctgan-0.11.0 decaf-synthetic-data-0.1.6 deepecho-0.7.0 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 fsspec-2025.3.0 geomloss-0.2.6 inflate64-1.0.3 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 loguru-0.7.3 monai-1.4.0 multivolumefile-0.2.3 networkx-2.8.8 nflows-0.14 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.4 pgmpy-0.1.26 py7zr-1.0.0 pybcj-1.0.6 pycox-0.3.0 pykeops-2.3 pyppmd-1.2.0 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.17.0 rdt-1.17.0 redis-6.2.0 scikit-learn-1.6.1 sdmetrics-0.21.0 sdv-1.22.1 synthcity-0.2.12 torch-2.2.2 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 xgboost-2.1.4 xgbse-0.3.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install opacus==1.4.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:22:53.158181Z","iopub.execute_input":"2025-06-08T23:22:53.158529Z","iopub.status.idle":"2025-06-08T23:22:57.940478Z","shell.execute_reply.started":"2025-06-08T23:22:53.158491Z","shell.execute_reply":"2025-06-08T23:22:57.939714Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"1V8Hz9-aaomn","outputId":"25abfd0b-2588-4193-9116-af20df77ebf7"},"outputs":[{"name":"stdout","text":"Collecting opacus==1.4.0\n  Downloading opacus-1.4.0-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (2.2.2)\nRequirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (1.15.2)\nRequirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (3.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->opacus==1.4.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (4.13.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.8.8)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->opacus==1.4.0) (12.9.41)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->opacus==1.4.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->opacus==1.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->opacus==1.4.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.15->opacus==1.4.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.15->opacus==1.4.0) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13->opacus==1.4.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.15->opacus==1.4.0) (2024.2.0)\nDownloading opacus-1.4.0-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opacus\n  Attempting uninstall: opacus\n    Found existing installation: opacus 1.5.4\n    Uninstalling opacus-1.5.4:\n      Successfully uninstalled opacus-1.5.4\nSuccessfully installed opacus-1.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !unrar x data.rar","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"il1DETirctj_","outputId":"fc05201d-9b10-460a-c5df-e91eb6bd3472","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:22:57.941550Z","iopub.execute_input":"2025-06-08T23:22:57.941825Z","iopub.status.idle":"2025-06-08T23:22:57.946091Z","shell.execute_reply.started":"2025-06-08T23:22:57.941798Z","shell.execute_reply":"2025-06-08T23:22:57.945340Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport random\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom hyperopt import fmin, rand, hp, Trials, STATUS_OK\nfrom hyperopt import space_eval\nfrom synthcity.plugins import Plugins\nfrom synthcity.plugins.generic.plugin_ddpm import TabDDPMPlugin as DDPM\nfrom sdv.metadata import SingleTableMetadata\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport tqdm\nfrom sklearn.metrics import f1_score, r2_score\nfrom xgboost import XGBClassifier, XGBRegressor","metadata":{"id":"xoQSvMHY8sJ_","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:22:57.947750Z","iopub.execute_input":"2025-06-08T23:22:57.947967Z","iopub.status.idle":"2025-06-08T23:23:58.423783Z","shell.execute_reply.started":"2025-06-08T23:22:57.947951Z","shell.execute_reply":"2025-06-08T23:23:58.423108Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"964de690-b773-4264-a2c0-ea0da04c6baf"},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749425002.367546      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749425002.473769      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[KeOps] Compiling cuda jit compiler engine ... OK\n[pyKeOps] Compiling nvrtc binder for python ... OK\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"    dir_datasets = '/kaggle/input/nir02-main/data/'\n\n    # Загрузка реальных датасетов\n    real_data_1 = pd.read_csv(dir_datasets+'insurance.csv')\n    real_data_2 = pd.read_csv(dir_datasets+'my_classification.csv')\n    real_data_3 = pd.read_csv(dir_datasets+'my_regression.csv')\n    real_data_4 = pd.read_csv(dir_datasets+'two_moons.csv')\n    real_data_5 = pd.read_csv(dir_datasets+'california_housing.csv')\n    real_data_6 = pd.read_csv(dir_datasets+'titanic.csv')\n\n    # Словарь датасетов для удобства\n    datasets = {\n        'insurance': {\n                        \"data\": real_data_1,\n                        \"task\": \"regression\",\n                        \"target\": \"expenses\",\n                        \"num_columns\":\n                        [\"age\", \"bmi\", \"children\"],\n                        \"cat_columns\":\n                        [\"sex\", \"smoker\", \"region\"]\n                    },\n        'my_classification': {\n                        \"data\": real_data_2,\n                        \"task\": \"classification\",\n                        \"target\": \"target\",\n                        \"num_columns\":\n                        [\"feature_0\", \"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"],\n                        \"cat_columns\":\n                        []\n                    },\n        'my_regression': {\n                        \"data\": real_data_3,\n                        \"task\": \"regression\",\n                        \"target\": \"target\",\n                        \"num_columns\":\n                        [\"feature_0\", \"feature_1\", \"feature_2\", \"feature_3\"],\n                        \"cat_columns\":\n                        []\n                    },\n\n        'california_housing': {\n                        \"data\": real_data_5,\n                        \"task\": \"regression\",\n                        \"target\": \"MedHouseVal\",\n                        \"num_columns\":\n                        [\"MedInc\",\t\"HouseAge\",\t\"AveRooms\",\t\"AveBedrms\",\t\"Population\",\t\"AveOccup\",\t\"Latitude\",\t\"Longitude\"],\n                        \"cat_columns\": \n                        []\n                    },\n        'titanic': {\n                        \"data\": real_data_6,\n                        \"task\": \"classification\",\n                        \"target\": \"Survived\",\n                        \"num_columns\": [\"Age\", \"Fare\", \"SibSp\", \"Parch\"],\n                        \"cat_columns\": [\"Pclass\", \"Sex\", \"Embarked\"]\n                    },\n        \n    }\n\n    for name, data in datasets.items():\n        print(f\" Информация о датасете {name}:\")\n        print(f\" Количество строк: {data['data'].shape[0]}\")\n        print(f\" Количество колонок: {data['data'].shape[1]}\")\n        print(f\" Колонки: {list(data['data'].columns)}\")\n        print(f\" Задача: {data['task']}\")\n        print(f\" Целевая переменная: {data['target']}\")\n        print(f\" Числовые признаки: {data['num_columns']}\")\n        print(f\" Категориальные признаки: {data['cat_columns']}\")\n        print()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKQZwZ93EGlS","outputId":"e9925253-60af-42b4-9a96-4a4616b2cccd","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.424537Z","iopub.execute_input":"2025-06-08T23:23:58.425361Z","iopub.status.idle":"2025-06-08T23:23:58.546145Z","shell.execute_reply.started":"2025-06-08T23:23:58.425332Z","shell.execute_reply":"2025-06-08T23:23:58.545351Z"}},"outputs":[{"name":"stdout","text":" Информация о датасете insurance:\n Количество строк: 1338\n Количество колонок: 7\n Колонки: ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'expenses']\n Задача: regression\n Целевая переменная: expenses\n Числовые признаки: ['age', 'bmi', 'children']\n Категориальные признаки: ['sex', 'smoker', 'region']\n\n Информация о датасете my_classification:\n Количество строк: 900\n Количество колонок: 6\n Колонки: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'target']\n Задача: classification\n Целевая переменная: target\n Числовые признаки: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']\n Категориальные признаки: []\n\n Информация о датасете my_regression:\n Количество строк: 900\n Количество колонок: 5\n Колонки: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'target']\n Задача: regression\n Целевая переменная: target\n Числовые признаки: ['feature_0', 'feature_1', 'feature_2', 'feature_3']\n Категориальные признаки: []\n\n Информация о датасете california_housing:\n Количество строк: 1200\n Количество колонок: 9\n Колонки: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'MedHouseVal']\n Задача: regression\n Целевая переменная: MedHouseVal\n Числовые признаки: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n Категориальные признаки: []\n\n Информация о датасете titanic:\n Количество строк: 712\n Количество колонок: 12\n Колонки: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n Задача: classification\n Целевая переменная: Survived\n Числовые признаки: ['Age', 'Fare', 'SibSp', 'Parch']\n Категориальные признаки: ['Pclass', 'Sex', 'Embarked']\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"RANDOM_SEED = 42\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(RANDOM_SEED)","metadata":{"id":"Fdy8sdZxFT1p","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.546977Z","iopub.execute_input":"2025-06-08T23:23:58.547239Z","iopub.status.idle":"2025-06-08T23:23:58.551920Z","shell.execute_reply.started":"2025-06-08T23:23:58.547219Z","shell.execute_reply":"2025-06-08T23:23:58.551083Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def process_data(dataset, num_columns, cat_columns, transformation_num_type='None', transformation_cat_type='None'):\n\n    df_processed = dataset.copy()\n\n    # Обработка числовых признаков\n    if transformation_num_type == 'CDF':\n        # CDF трансформация: преобразует значения в их эмпирическую функцию распределения\n        for col in num_columns:\n            # Правильная формула для эмпирической CDF\n            df_processed[col] = (df_processed[col].rank(method='average') - 0.5) / len(df_processed)\n\n    elif transformation_num_type == 'PLE_CDF':\n        # PLE_CDF (Probability Logit Envelope CDF) - более сложная трансформация\n        for col in num_columns:\n            # Сначала применяем CDF\n            cdf_values = (df_processed[col].rank(method='average') - 0.5) / len(df_processed)\n\n            # Затем применяем logit трансформацию с небольшим сглаживанием\n            # Избегаем 0 и 1 для предотвращения бесконечности в logit\n            epsilon = 1e-6\n            cdf_values = np.clip(cdf_values, epsilon, 1 - epsilon)\n\n            # Логит трансформация: ln(p/(1-p))\n            df_processed[col] = np.log(cdf_values / (1 - cdf_values))\n\n    # Обработка категориальных признаков\n    if transformation_cat_type == 'OHE':\n        # One Hot Encoding для категориальных признаков\n        for col in cat_columns:\n            # Создаем dummy переменные с префиксом имени колонки\n            dummy_df = pd.get_dummies(df_processed[col], prefix=col, dtype=int)\n\n            # Удаляем исходную категориальную колонку\n            df_processed = df_processed.drop(columns=[col])\n\n            # Добавляем новые dummy колонки\n            df_processed = pd.concat([df_processed, dummy_df], axis=1)\n\n    return df_processed","metadata":{"id":"NonvG7oNFVXd","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.552726Z","iopub.execute_input":"2025-06-08T23:23:58.552938Z","iopub.status.idle":"2025-06-08T23:23:58.563042Z","shell.execute_reply.started":"2025-06-08T23:23:58.552920Z","shell.execute_reply":"2025-06-08T23:23:58.562244Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Определение пространства поиска гиперпараметров для DDPM\nddpm_space = {\n    'batch_size': hp.choice('batch_size', [4096]),\n    'lr': hp.qloguniform('lr', np.log(3.5e-4), np.log(9.2e-4), 1e-5),\n    'num_timesteps': hp.choice('num_timesteps', [1000]),\n    'n_layers_hidden': hp.choice('n_layers_hidden', [2, 4, 6]),\n    'n_units_hidden': hp.choice('n_units_hidden', [256, 512, 1024]),\n    'transformation_num_type': hp.choice('transformation_num_type', ['None']),\n    'transformation_cat_type': hp.choice('transformation_cat_type', ['None'])\n}","metadata":{"id":"ge6z2nc4HRii","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.563993Z","iopub.execute_input":"2025-06-08T23:23:58.564379Z","iopub.status.idle":"2025-06-08T23:23:58.581128Z","shell.execute_reply.started":"2025-06-08T23:23:58.564344Z","shell.execute_reply":"2025-06-08T23:23:58.580473Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def evaluate_ml_efficacy(real_train, synthetic_train, real_test, target_column, num_columns, cat_columns, task_type='classification'):\n    \"\"\"\n    Вычисляет ML-Efficacy метрику\n\n    Args:\n        real_train: реальные тренировочные данные\n        synthetic_train: синтетические тренировочные данные\n        real_test: реальные тестовые данные\n        target_column: название целевой колонки\n        task_type: 'classification' или 'regression'\n\n    Returns:\n        ml_efficacy_score: отношение качества модели на синтетических данных к качеству на реальных\n    \"\"\"\n\n    # Подготовка данных\n    real_train_copy = real_train.copy()\n\n    # Обработка синтетических данных (если это объект с методом dataframe)\n    if hasattr(synthetic_train, \"dataframe\"):\n        synthetic_train = synthetic_train.dataframe()\n    synthetic_train_copy = synthetic_train.copy()\n\n    real_test_copy = real_test.copy()\n\n    # Определение категориальных колонок (исключая целевую)\n    feature_columns = num_columns\n    categorical_columns = cat_columns\n\n    # Label Encoding для категориальных признаков\n    label_encoders = {}\n    for col in categorical_columns:\n        le = LabelEncoder()\n        # Обучаем на реальных данных\n        combined_values = pd.concat([real_train_copy[col], real_test_copy[col]]).astype(str)\n        le.fit(combined_values)\n        label_encoders[col] = le\n\n        # Применяем к реальным данным\n        real_train_copy[col] = le.transform(real_train_copy[col].astype(str))\n        real_test_copy[col] = le.transform(real_test_copy[col].astype(str))\n\n        # Применяем к синтетическим данным, обрабатываем неизвестные значения\n        synthetic_values = synthetic_train_copy[col].astype(str)\n        known_values = set(le.classes_)\n        synthetic_values = synthetic_values.apply(lambda x: x if x in known_values else le.classes_[0])\n        synthetic_train_copy[col] = le.transform(synthetic_values)\n\n    # Разделение на признаки и целевую переменную\n    X_real_train = real_train_copy.drop(columns=[target_column])\n    y_real_train = real_train_copy[target_column]\n\n    X_synthetic_train = synthetic_train_copy.drop(columns=[target_column])\n    y_synthetic_train = synthetic_train_copy[target_column]\n\n    X_real_test = real_test_copy.drop(columns=[target_column])\n    y_real_test = real_test_copy[target_column]\n\n    # Выбор модели в зависимости от типа задачи\n    if task_type == 'classification':\n        model_real = XGBClassifier(random_state=42, eval_metric='logloss')\n        model_synthetic = XGBClassifier(random_state=42, eval_metric='logloss')\n        score_func = f1_score\n        score_kwargs = {'average': 'weighted'} if len(np.unique(y_real_train)) > 2 else {'average': 'binary'}\n    else:  # regression\n        model_real = XGBRegressor(random_state=42)\n        model_synthetic = XGBRegressor(random_state=42)\n        score_func = r2_score\n        score_kwargs = {}\n\n    try:\n        # Обучение модели на реальных данных\n        model_real.fit(X_real_train, y_real_train)\n        y_pred_real = model_real.predict(X_real_test)\n        score_real = score_func(y_real_test, y_pred_real, **score_kwargs)\n\n        # Обучение модели на синтетических данных\n        model_synthetic.fit(X_synthetic_train, y_synthetic_train)\n        y_pred_synthetic = model_synthetic.predict(X_real_test)\n        score_synthetic = score_func(y_real_test, y_pred_synthetic, **score_kwargs)\n\n        # Вычисление ML-Efficacy\n        if score_real > 0:\n            ml_efficacy = score_synthetic / score_real\n        else:\n            ml_efficacy = 0.0\n\n        return ml_efficacy\n\n    except Exception as e:\n        print(f\"Ошибка при вычислении ML-Efficacy: {e}\")\n        return 0.0","metadata":{"id":"n-9yfPplIRvC","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.582149Z","iopub.execute_input":"2025-06-08T23:23:58.582696Z","iopub.status.idle":"2025-06-08T23:23:58.598627Z","shell.execute_reply.started":"2025-06-08T23:23:58.582668Z","shell.execute_reply":"2025-06-08T23:23:58.597785Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import sys\nimport os\nimport builtins\nimport contextlib\n\n@contextlib.contextmanager\ndef suppress_all_output():\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        old_stderr = sys.stderr\n        old_print = builtins.print\n        builtins.print = lambda *args, **kwargs: None\n        sys.stdout = devnull\n        sys.stderr = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr\n            builtins.print = old_print","metadata":{"id":"tU79Ih1dOWMM","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.601090Z","iopub.execute_input":"2025-06-08T23:23:58.601783Z","iopub.status.idle":"2025-06-08T23:23:58.615489Z","shell.execute_reply.started":"2025-06-08T23:23:58.601762Z","shell.execute_reply":"2025-06-08T23:23:58.614897Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef generate_and_evaluate_ml_efficacy(params, dataset_info, n_splits=3):\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n\n    # Извлекаем информацию о задаче и целевой переменной из dataset_info\n    task_type = dataset_info['task']\n    target_column = dataset_info['target']\n\n    columns_dataset = dataset_info['num_columns'] + dataset_info['cat_columns'] + [dataset_info['target']]\n    data = process_data(dataset_info['data'][columns_dataset], dataset_info['num_columns'], dataset_info['cat_columns'],\n                        params['transformation_num_type'], params['transformation_cat_type'])\n\n    kf = KFold(n_splits=n_splits, shuffle=False)\n    ml_efficacy_scores = []\n\n    for train_index, test_index in kf.split(data):\n        train_data = data.iloc[train_index].reset_index(drop=True)\n        test_data = data.iloc[test_index].reset_index(drop=True)\n\n        metadata = SingleTableMetadata()\n        metadata.detect_from_dataframe(data=train_data)\n\n        # Создание и обучение DDPM с заданными параметрами\n        ddpm = DDPM(\n            lr=params['lr'],\n            num_timesteps=params['num_timesteps'],\n            model_params = dict(n_layers_hidden=params['n_layers_hidden'],\n                                n_units_hidden=params['n_units_hidden'],\n                                dropout=0.0),\n            batch_size=params['batch_size']\n        )\n\n        # Обучение модели на реальных данных\n        with suppress_all_output():\n            ddpm.fit(train_data)\n\n        # Генерация синтетических данных\n        synthetic_data = ddpm.generate(len(train_data))\n\n        cat_columns = dataset_info[\"cat_columns\"].copy()\n        if dataset_info[\"task\"] == 'classification':\n            cat_columns.append(dataset_info['target'])\n\n        # Вычисляем ML-Efficacy\n        score = evaluate_ml_efficacy(\n            real_train=train_data,\n            synthetic_train=synthetic_data,\n            real_test=test_data,\n            target_column=target_column,\n            num_columns = dataset_info[\"num_columns\"],\n            cat_columns = cat_columns,\n            task_type=task_type\n        )\n        ml_efficacy_scores.append(score)\n\n    return np.mean(ml_efficacy_scores)","metadata":{"id":"YR4_7KpJI0wX","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.616506Z","iopub.execute_input":"2025-06-08T23:23:58.616840Z","iopub.status.idle":"2025-06-08T23:23:58.629615Z","shell.execute_reply.started":"2025-06-08T23:23:58.616815Z","shell.execute_reply":"2025-06-08T23:23:58.628989Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def optimize_dataset(dataset_name, dataset_info, max_evals=30):\n    print(f\"Оптимизация для датасета: {dataset_name}\")\n\n    # Создаем объект для хранения истории поиска\n    trials = Trials()\n\n    # Определяем целевую функцию для оптимизации\n    def objective(params):\n        print(\"=\"*50)\n        ml_efficacy_score = generate_and_evaluate_ml_efficacy(params, dataset_info)\n\n        print(f\"ML-Efficacy: {ml_efficacy_score}\")\n        print(params)\n        print(\"=\"*50)\n\n        # Для ML-Efficacy мы хотим максимизировать метрику, поэтому возвращаем отрицательное значение\n        return {\n            'loss': -ml_efficacy_score,  # отрицательное для максимизации\n            'status': STATUS_OK,\n            'ml_efficacy_score': ml_efficacy_score\n        }\n\n    # Запускаем оптимизацию с помощью TPE алгоритма\n    rng = np.random.default_rng(42)  # Используем фиксированный seed\n    best = fmin(\n        fn=objective,\n        space=ddpm_space,\n        algo=rand.suggest,\n        max_evals=max_evals,\n        trials=trials,\n        rstate=rng\n    )\n\n    # Автоматическое декодирование параметров\n    best_params = space_eval(ddpm_space, best)\n\n    # Находим лучший результат\n    best_trial = min(trials.trials, key=lambda x: x['result']['loss'])\n    best_ml_efficacy = best_trial['result'].get('ml_efficacy_score', None)\n\n    results = {\n        'best_params': best_params,\n        'best_ml_efficacy': best_ml_efficacy,\n        'ml_efficacy_diff_from_optimal': -best_trial['result']['loss']  # убираем минус для читаемости\n    }\n\n    print(f\"Лучший ML-Efficacy для {dataset_name}: {best_ml_efficacy}\")\n    print(f\"Лучшие параметры: {best_params}\")\n    print('-' * 50)\n\n    return results","metadata":{"id":"vD2xqTjyNSG5","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:23:58.630410Z","iopub.execute_input":"2025-06-08T23:23:58.630722Z","iopub.status.idle":"2025-06-08T23:23:58.647999Z","shell.execute_reply.started":"2025-06-08T23:23:58.630697Z","shell.execute_reply":"2025-06-08T23:23:58.647353Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Словарь для хранения результатов\nall_results = {}\n\n# Указываем количество итераций для каждого датасета\nmax_evals = 50\n\n# Запускаем оптимизацию для каждого датасета\nfor dataset_name in datasets:\n    data = datasets[dataset_name]\n    all_results[dataset_name] = optimize_dataset(dataset_name, data, max_evals)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZmVmaNlNaVG","outputId":"489132c2-5863-42e0-b2a5-3e55b7107a93","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T23:34:49.650258Z","iopub.execute_input":"2025-06-08T23:34:49.650656Z","execution_failed":"2025-06-09T08:26:56.004Z"}},"outputs":[{"name":"stdout","text":"Оптимизация для датасета: insurance\n==================================================    \nML-Efficacy: 0.892637484402648                        \n{'batch_size': 4096, 'lr': 0.00064, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================    \n==================================================                                 \nML-Efficacy: 0.04167971727276106                                                   \n{'batch_size': 4096, 'lr': 0.00063, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: -0.092370388782063                                                    \n{'batch_size': 4096, 'lr': 0.00038, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: 0.7236053891091205                                                    \n{'batch_size': 4096, 'lr': 0.00043000000000000004, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: 0.7248813729319395                                                    \n{'batch_size': 4096, 'lr': 0.00038, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: 0.8159618406328183                                                    \n{'batch_size': 4096, 'lr': 0.00041000000000000005, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: -2.860622355036417                                                    \n{'batch_size': 4096, 'lr': 0.00092, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: 0.5518762857089375                                                    \n{'batch_size': 4096, 'lr': 0.0007800000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: 0.8518830020181324                                                    \n{'batch_size': 4096, 'lr': 0.0007400000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                 \nML-Efficacy: -0.10960758293291116                                                  \n{'batch_size': 4096, 'lr': 0.0005600000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                 \n==================================================                                  \nML-Efficacy: -0.37333581886204964                                                   \n{'batch_size': 4096, 'lr': 0.00036, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: 0.36411520112855356                                                    \n{'batch_size': 4096, 'lr': 0.00063, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: 0.6520818133105527                                                     \n{'batch_size': 4096, 'lr': 0.00071, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: -2.7855687071252366                                                    \n{'batch_size': 4096, 'lr': 0.00055, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: 0.5601339123701656                                                     \n{'batch_size': 4096, 'lr': 0.00084, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: 0.8042903380879612                                                     \n{'batch_size': 4096, 'lr': 0.0009100000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                  \n==================================================                                  \nML-Efficacy: -0.5972143414166731                                                    \n{'batch_size': 4096, 'lr': 0.0007700000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.4861603489185414                                                       \n{'batch_size': 4096, 'lr': 0.00039000000000000005, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.3559279924989773                                                       \n{'batch_size': 4096, 'lr': 0.0008, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.8729720925998593                                                       \n{'batch_size': 4096, 'lr': 0.0007000000000000001, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.8838382908660924                                                       \n{'batch_size': 4096, 'lr': 0.00068, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.653889562408699                                                        \n{'batch_size': 4096, 'lr': 0.00041000000000000005, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.7929979847055293                                                       \n{'batch_size': 4096, 'lr': 0.00079, 'n_layers_hidden': 4, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nML-Efficacy: 0.9122763050016469                                                       \n{'batch_size': 4096, 'lr': 0.0006900000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                     \nML-Efficacy: 0.6494914160263794                                                        \n{'batch_size': 4096, 'lr': 0.00046, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.653889562408699                                                         \n{'batch_size': 4096, 'lr': 0.00041000000000000005, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.7444332102553316                                                        \n{'batch_size': 4096, 'lr': 0.0009000000000000001, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.5771238984293872                                                        \n{'batch_size': 4096, 'lr': 0.0007300000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.7931269018598842                                                      \n{'batch_size': 4096, 'lr': 0.00067, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.45477774745934374                                                     \n{'batch_size': 4096, 'lr': 0.0006600000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.7098118686305482                                                      \n{'batch_size': 4096, 'lr': 0.00043000000000000004, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.7032178580814964                                                      \n{'batch_size': 4096, 'lr': 0.00044, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: -2.860622355036417                                                      \n{'batch_size': 4096, 'lr': 0.00092, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                     \nML-Efficacy: -0.9228731116235748                                                       \n{'batch_size': 4096, 'lr': 0.00072, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.7751233039451774                                                        \n{'batch_size': 4096, 'lr': 0.0005200000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.8399181856045183                                                        \n{'batch_size': 4096, 'lr': 0.00054, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                     \n==================================================                                     \nML-Efficacy: 0.5493527397280544                                                      \n{'batch_size': 4096, 'lr': 0.0008300000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.794668955133424                                                       \n{'batch_size': 4096, 'lr': 0.00062, 'n_layers_hidden': 4, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.754468911436624                                                       \n{'batch_size': 4096, 'lr': 0.0004, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.7105338253826843                                                      \n{'batch_size': 4096, 'lr': 0.00047000000000000004, 'n_layers_hidden': 4, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.48633599735713146                                                     \n{'batch_size': 4096, 'lr': 0.0004, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: -11.78076123999577                                                      \n{'batch_size': 4096, 'lr': 0.00088, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.30398727654761026                                                     \n{'batch_size': 4096, 'lr': 0.00043000000000000004, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.5547602459804345                                                      \n{'batch_size': 4096, 'lr': 0.0009000000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: -0.9450792735274843                                                     \n{'batch_size': 4096, 'lr': 0.0004900000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.8123616822221505                                                      \n{'batch_size': 4096, 'lr': 0.0006500000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.7880878234387311                                                      \n{'batch_size': 4096, 'lr': 0.0007700000000000001, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nML-Efficacy: 0.4060446126542347                                                      \n{'batch_size': 4096, 'lr': 0.0005700000000000001, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \n 96%|█████████▌| 48/50 [2:56:26<05:51, 175.81s/trial, best loss: -0.9122763050016469]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"for dataset_name in datasets:\n    print(dataset_name, all_results[dataset_name]['best_ml_efficacy'])","metadata":{"id":"-VGL5IBfVYnK","trusted":true,"execution":{"execution_failed":"2025-06-09T08:26:56.004Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"06f172e8-f41f-47c4-c689-cdd3cc7a3fbf"},"outputs":[],"execution_count":null}]}