{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12040372,"sourceType":"datasetVersion","datasetId":7576541}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy==1.24.4 --force-reinstall --no-deps\n!pip install scipy==1.10.1 --force-reinstall\n\n!pip install --upgrade torch torchvision torchaudio\n\n!pip install networkx==2.8.8 --force-reinstall\n\n!pip install scikit-learn==1.4.2 --force-reinstall\n\n!pip install synthcity==0.2.12\n!pip install opacus==1.4.0\n\n!pip install hyperopt==0.2.7\n!pip install xgboost==2.0.3","metadata":{"execution":{"iopub.status.busy":"2025-06-03T10:36:04.442061Z","iopub.execute_input":"2025-06-03T10:36:04.442745Z","iopub.status.idle":"2025-06-03T10:42:52.137979Z","shell.execute_reply.started":"2025-06-03T10:36:04.442711Z","shell.execute_reply":"2025-06-03T10:42:52.137176Z"},"id":"ViQ1KuKFN8mR","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"63e5354c-e396-4ebb-b4ff-1d96ae2a5ec1"},"outputs":[{"name":"stdout","text":"Collecting numpy==1.24.4\n  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\nSuccessfully installed numpy-1.24.4\nCollecting scipy==1.10.1\n  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy<1.27.0,>=1.19.5 (from scipy==1.10.1)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scipy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.4\n    Uninstalling numpy-1.24.4:\n      Successfully uninstalled numpy-1.24.4\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\nkaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\njax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nscikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\ncvxpy 1.6.4 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\njaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.10.1\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting torch\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nCollecting torchvision\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting torchaudio\n  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nCollecting sympy>=1.13.3 (from torch)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.6.0+cu124\n    Uninstalling torchaudio-2.6.0+cu124:\n      Successfully uninstalled torchaudio-2.6.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0\nCollecting networkx==2.8.8\n  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\nDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: networkx\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.4.2\n    Uninstalling networkx-3.4.2:\n      Successfully uninstalled networkx-3.4.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nscikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed networkx-2.8.8\nCollecting scikit-learn==1.4.2\n  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting numpy>=1.19.5 (from scikit-learn==1.4.2)\n  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy>=1.6.0 (from scikit-learn==1.4.2)\n  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn==1.4.2)\n  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting threadpoolctl>=2.0.0 (from scikit-learn==1.4.2)\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n  Attempting uninstall: threadpoolctl\n    Found existing installation: threadpoolctl 3.6.0\n    Uninstalling threadpoolctl-3.6.0:\n      Successfully uninstalled threadpoolctl-3.6.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.5.0\n    Uninstalling joblib-1.5.0:\n      Successfully uninstalled joblib-1.5.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.10.1\n    Uninstalling scipy-1.10.1:\n      Successfully uninstalled scipy-1.10.1\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed joblib-1.5.1 numpy-2.2.6 scikit-learn-1.4.2 scipy-1.15.3 threadpoolctl-3.6.0\nCollecting synthcity==0.2.12\n  Downloading synthcity-0.2.12-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (8.7.0)\nRequirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (2.2.3)\nCollecting torch<2.3,>=2.1 (from synthcity==0.2.12)\n  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (1.4.2)\nCollecting nflows>=0.14 (from synthcity==0.2.12)\n  Downloading nflows-0.14.tar.gz (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting numpy<2.0,>=1.20 (from synthcity==0.2.12)\n  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting lifelines<0.30.0,>=0.29.0 (from synthcity==0.2.12)\n  Downloading lifelines-0.29.0-py3-none-any.whl.metadata (3.2 kB)\nCollecting opacus>=1.3 (from synthcity==0.2.12)\n  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: networkx<3.0,>2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (2.8.8)\nCollecting decaf-synthetic-data>=0.1.6 (from synthcity==0.2.12)\n  Downloading decaf_synthetic_data-0.1.6-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (4.3.0)\nRequirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (0.44.1)\nRequirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (9.1.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (4.67.1)\nCollecting loguru (from synthcity==0.2.12)\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (2.11.4)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (3.1.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (1.15.3)\nRequirement already satisfied: xgboost<3.0.0 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (2.0.3)\nCollecting geomloss (from synthcity==0.2.12)\n  Downloading geomloss-0.2.6.tar.gz (26 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pgmpy<1.0 (from synthcity==0.2.12)\n  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\nCollecting redis (from synthcity==0.2.12)\n  Downloading redis-6.2.0-py3-none-any.whl.metadata (10 kB)\nCollecting pycox (from synthcity==0.2.12)\n  Downloading pycox-0.3.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting xgbse>=0.3.1 (from synthcity==0.2.12)\n  Downloading xgbse-0.3.3-py3-none-any.whl.metadata (17 kB)\nCollecting pykeops (from synthcity==0.2.12)\n  Downloading pykeops-2.3.tar.gz (552 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting fflows (from synthcity==0.2.12)\n  Downloading fflows-0.0.3-py3-none-any.whl.metadata (3.4 kB)\nCollecting monai (from synthcity==0.2.12)\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nCollecting tsai (from synthcity==0.2.12)\n  Downloading tsai-0.4.0-py3-none-any.whl.metadata (16 kB)\nCollecting be-great>=0.0.5 (from synthcity==0.2.12)\n  Downloading be_great-0.0.9-py3-none-any.whl.metadata (5.8 kB)\nCollecting arfpy (from synthcity==0.2.12)\n  Downloading arfpy-0.1.1.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: fastcore<1.8 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (1.7.29)\nRequirement already satisfied: fastai<2.8 in /usr/local/lib/python3.11/dist-packages (from synthcity==0.2.12) (2.7.19)\nRequirement already satisfied: datasets>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity==0.2.12) (3.6.0)\nRequirement already satisfied: transformers>=4.22.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity==0.2.12) (4.51.3)\nRequirement already satisfied: accelerate>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from be-great>=0.0.5->synthcity==0.2.12) (1.5.2)\nCollecting pytorch-lightning<2.0 (from decaf-synthetic-data>=0.1.6->synthcity==0.2.12)\n  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\nCollecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity==0.2.12)\n  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (25.0)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (0.0.7)\nRequirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (0.22.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (3.7.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (2.32.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (6.0.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (1.0.3)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (11.1.0)\nRequirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8->synthcity==0.2.12) (3.8.5)\nRequirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines<0.30.0,>=0.29.0->synthcity==0.2.12) (1.7.0)\nCollecting autograd-gamma>=0.3 (from lifelines<0.30.0,>=0.29.0->synthcity==0.2.12)\n  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting formulaic>=0.2.2 (from lifelines<0.30.0,>=0.29.0->synthcity==0.2.12)\n  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nflows>=0.14->synthcity==0.2.12) (2.18.0)\nRequirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus>=1.3->synthcity==0.2.12) (3.4.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity==0.2.12) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity==0.2.12) (6.9.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->synthcity==0.2.12) (2.0.40)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity==0.2.12) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity==0.2.12) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->synthcity==0.2.12) (2025.2)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity==0.2.12) (3.0.9)\nRequirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity==0.2.12) (0.14.4)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity==0.2.12) (1.5.1)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (from pgmpy<1.0->synthcity==0.2.12) (0.8.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity==0.2.12) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity==0.2.12) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity==0.2.12) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->synthcity==0.2.12) (0.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->synthcity==0.2.12) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity==0.2.12) (3.18.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity==0.2.12) (1.14.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity==0.2.12) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->synthcity==0.2.12) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->synthcity==0.2.12) (12.6.85)\nCollecting scikit-learn>=1.2 (from synthcity==0.2.12)\n  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting xgboost<3.0.0 (from synthcity==0.2.12)\n  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->synthcity==0.2.12) (3.21.0)\nCollecting torchtuples>=0.2.0 (from pycox->synthcity==0.2.12)\n  Downloading torchtuples-0.2.2-py3-none-any.whl.metadata (3.8 kB)\nCollecting feather-format>=0.4.0 (from pycox->synthcity==0.2.12)\n  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity==0.2.12) (3.13.0)\nRequirement already satisfied: numba>=0.44 in /usr/local/lib/python3.11/dist-packages (from pycox->synthcity==0.2.12) (0.60.0)\nCollecting py7zr>=0.11.3 (from pycox->synthcity==0.2.12)\n  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from pykeops->synthcity==0.2.12) (2.13.6)\nCollecting keopscore==2.3 (from pykeops->synthcity==0.2.12)\n  Downloading keopscore-2.3.tar.gz (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap->synthcity==0.2.12) (0.0.7)\nCollecting pyts>=0.13.0 (from tsai->synthcity==0.2.12)\n  Downloading pyts-0.13.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: imbalanced-learn>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity==0.2.12) (0.13.0)\nRequirement already satisfied: psutil>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from tsai->synthcity==0.2.12) (7.0.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity==0.2.12) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.1->be-great>=0.0.5->synthcity==0.2.12) (0.5.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna>=3.1->synthcity==0.2.12) (1.3.10)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (0.70.16)\nCollecting fsspec (from torch<2.3,>=2.1->synthcity==0.2.12)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity==0.2.12)\n  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines<0.30.0,>=0.29.0->synthcity==0.2.12) (1.17.2)\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.4->tsai->synthcity==0.2.12) (0.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity==0.2.12) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity==0.2.12) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity==0.2.12) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai<2.8->synthcity==0.2.12) (1.4.8)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.44->pycox->synthcity==0.2.12) (0.43.0)\nRequirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity==0.2.12) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr>=0.11.3->pycox->synthcity==0.2.12) (3.22.0)\nCollecting brotli>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting pyzstd>=0.16.1 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting pyppmd<1.3.0,>=1.1.0 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr>=0.11.3->pycox->synthcity==0.2.12)\n  Downloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->synthcity==0.2.12) (1.17.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity==0.2.12) (1.7.1)\nRequirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0->decaf-synthetic-data>=0.1.6->synthcity==0.2.12) (0.14.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity==0.2.12) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity==0.2.12) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity==0.2.12) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->fastai<2.8->synthcity==0.2.12) (2025.4.26)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (0.15.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (75.2.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai<2.8->synthcity==0.2.12) (3.5.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->synthcity==0.2.12) (3.1.1)\nINFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\nCollecting torchtext>=0.10 (from decaf-synthetic-data>=0.1.6->synthcity==0.2.12)\n  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision>=0.11 (from fastai<2.8->synthcity==0.2.12)\n  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity==0.2.12) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.22.1->be-great>=0.0.5->synthcity==0.2.12) (0.21.1)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity==0.2.12) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity==0.2.12) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity==0.2.12) (2.164.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity==0.2.12) (2.40.1)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai->pgmpy<1.0->synthcity==0.2.12) (3.20.3)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (1.26.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->synthcity==0.2.12) (3.0.2)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy<1.0->synthcity==0.2.12) (1.0.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->synthcity==0.2.12) (1.3.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity==0.2.12) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity==0.2.12) (1.72.0rc1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity==0.2.12) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity==0.2.12) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nflows>=0.14->synthcity==0.2.12) (3.1.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (3.11.18)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (4.9.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.1->be-great>=0.0.5->synthcity==0.2.12) (1.1.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity==0.2.12) (1.3.0)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity==0.2.12) (1.2.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai<2.8->synthcity==0.2.12) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity==0.2.12) (0.21.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8->synthcity==0.2.12) (7.1.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (4.1.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.5.2->be-great>=0.0.5->synthcity==0.2.12) (1.20.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (1.49.0rc1)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8->synthcity==0.2.12) (1.2.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy<1.0->synthcity==0.2.12) (0.6.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8->synthcity==0.2.12) (0.1.2)\nDownloading synthcity-0.2.12-py3-none-any.whl (434 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.3/434.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading be_great-0.0.9-py3-none-any.whl (19 kB)\nDownloading decaf_synthetic_data-0.1.6-py3-none-any.whl (9.1 kB)\nDownloading lifelines-0.29.0-py3-none-any.whl (349 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\nDownloading opacus-1.5.4-py3-none-any.whl (254 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m364.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgbse-0.3.3-py3-none-any.whl (35 kB)\nDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fflows-0.0.3-py3-none-any.whl (19 kB)\nDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycox-0.3.0-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading redis-6.2.0-py3-none-any.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tsai-0.4.0-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.3/324.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\nDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nflows, arfpy, geomloss, pykeops, keopscore, autograd-gamma, feather-format\n  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53654 sha256=1c06d98b6ccca36205f6e92847c6dfb2c44c4b6a1046cca2a1303cb70b56f4c9\n  Stored in directory: /root/.cache/pip/wheels/11/9d/b5/5c88631a7bdb388738d147b6a28ba435ab969f25eff552f75a\n  Building wheel for arfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for arfpy: filename=arfpy-0.1.1-py3-none-any.whl size=8664 sha256=f0cba1a163cf3fe92f561cbcdd9a962f4e97f35fe2080db54493aec0278bd982\n  Stored in directory: /root/.cache/pip/wheels/9b/9a/2b/0414258a3b781854c07acca132cf155a7d93b69f23c3cd6826\n  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=abbc66d56e9682fd8cf0712f00b8eb3bfb9c4bc57dfcea42dae0a69f54664bf7\n  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pykeops: filename=pykeops-2.3-py3-none-any.whl size=120491 sha256=222f2574e880222c7556df58009514ab9c723ff0f3963f4b6321bd5d37200740\n  Stored in directory: /root/.cache/pip/wheels/a8/91/ea/d9e54997a840e38595b9a2c5b9021f3969173edbda2fc99686\n  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keopscore: filename=keopscore-2.3-py3-none-any.whl size=185897 sha256=715ba6ef7f0ae64ab2f0cbb6ad8fd8c43ade0867154382aee09b13b4ac6dc3dd\n  Stored in directory: /root/.cache/pip/wheels/32/77/92/17707f162cb65cfa8e97f0360cdb30681038f7762cf929b1b4\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=99690fcdde2a5a7cc853e9cc7cdff7bfdf669b1ee329688864911719c03a5948\n  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n  Building wheel for feather-format (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2434 sha256=b0bf18b3339579372f89b33da8fb6e306c3a12224c62c0b06dc70af4e2d7a0ef\n  Stored in directory: /root/.cache/pip/wheels/77/5b/0e/0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\nSuccessfully built nflows arfpy geomloss pykeops keopscore autograd-gamma feather-format\nInstalling collected packages: brotli, triton, redis, pyzstd, pyppmd, pybcj, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multivolumefile, loguru, keopscore, interface-meta, inflate64, fsspec, feather-format, pykeops, py7zr, nvidia-cusolver-cu12, nvidia-cudnn-cu12, xgboost, torch, scikit-learn, formulaic, autograd-gamma, torchvision, torchtuples, torchtext, pyts, opacus, nflows, monai, lifelines, geomloss, fflows, arfpy, xgbse, pytorch-lightning, pycox, be-great, decaf-synthetic-data, tsai, pgmpy, synthcity\n  Attempting uninstall: triton\n    Found existing installation: triton 3.3.0\n    Uninstalling triton-3.3.0:\n      Successfully uninstalled triton-3.3.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.26.2\n    Uninstalling nvidia-nccl-cu12-2.26.2:\n      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.2.6\n    Uninstalling numpy-2.2.6:\n      Successfully uninstalled numpy-2.2.6\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.0.3\n    Uninstalling xgboost-2.0.3:\n      Successfully uninstalled xgboost-2.0.3\n  Attempting uninstall: torch\n    Found existing installation: torch 2.7.0\n    Uninstalling torch-2.7.0:\n      Successfully uninstalled torch-2.7.0\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.4.2\n    Uninstalling scikit-learn-1.4.2:\n      Successfully uninstalled scikit-learn-1.4.2\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.22.0\n    Uninstalling torchvision-0.22.0:\n      Successfully uninstalled torchvision-0.22.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.5.1.post0\n    Uninstalling pytorch-lightning-2.5.1.post0:\n      Successfully uninstalled pytorch-lightning-2.5.1.post0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.7.0 requires torch==2.7.0, but you have torch 2.2.2 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed arfpy-0.1.1 autograd-gamma-0.5.0 be-great-0.0.9 brotli-1.1.0 decaf-synthetic-data-0.1.6 feather-format-0.4.1 fflows-0.0.3 formulaic-1.1.1 fsspec-2025.3.0 geomloss-0.2.6 inflate64-1.0.3 interface-meta-1.3.0 keopscore-2.3 lifelines-0.29.0 loguru-0.7.3 monai-1.4.0 multivolumefile-0.2.3 nflows-0.14 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opacus-1.5.4 pgmpy-0.1.26 py7zr-1.0.0 pybcj-1.0.6 pycox-0.3.0 pykeops-2.3 pyppmd-1.2.0 pytorch-lightning-1.9.5 pyts-0.13.0 pyzstd-0.17.0 redis-6.2.0 scikit-learn-1.6.1 synthcity-0.2.12 torch-2.2.2 torchtext-0.17.2 torchtuples-0.2.2 torchvision-0.17.2 triton-2.2.0 tsai-0.4.0 xgboost-2.1.4 xgbse-0.3.3\nCollecting opacus==1.4.0\n  Downloading opacus-1.4.0-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (2.2.2)\nRequirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (1.15.3)\nRequirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus==1.4.0) (3.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (4.13.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.8.8)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->opacus==1.4.0) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->opacus==1.4.0) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->opacus==1.4.0) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13->opacus==1.4.0) (1.3.0)\nDownloading opacus-1.4.0-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opacus\n  Attempting uninstall: opacus\n    Found existing installation: opacus 1.5.4\n    Uninstalling opacus-1.5.4:\n      Successfully uninstalled opacus-1.5.4\nSuccessfully installed opacus-1.4.0\nRequirement already satisfied: hyperopt==0.2.7 in /usr/local/lib/python3.11/dist-packages (0.2.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (1.15.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (1.17.0)\nRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (2.8.8)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (1.0.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (4.67.1)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (3.1.1)\nRequirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt==0.2.7) (0.10.9.7)\nCollecting xgboost==2.0.3\n  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.0.3) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost==2.0.3) (1.15.3)\nDownloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xgboost\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.1.4\n    Uninstalling xgboost-2.1.4:\n      Successfully uninstalled xgboost-2.1.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nxgbse 0.3.3 requires xgboost<3.0.0,>=2.1.0, but you have xgboost 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed xgboost-2.0.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install sdmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T10:52:09.919971Z","iopub.execute_input":"2025-06-03T10:52:09.920933Z","iopub.status.idle":"2025-06-03T10:52:14.120915Z","shell.execute_reply.started":"2025-06-03T10:52:09.920907Z","shell.execute_reply":"2025-06-03T10:52:14.120098Z"}},"outputs":[{"name":"stdout","text":"Collecting sdmetrics\n  Downloading sdmetrics-0.21.0-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (1.26.4)\nRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (2.2.3)\nRequirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (1.6.1)\nRequirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (1.15.3)\nCollecting copulas>=0.12.1 (from sdmetrics)\n  Downloading copulas-0.12.2-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (4.67.1)\nRequirement already satisfied: plotly>=5.19.0 in /usr/local/lib/python3.11/dist-packages (from sdmetrics) (5.24.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdmetrics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdmetrics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdmetrics) (2025.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.19.0->sdmetrics) (9.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.19.0->sdmetrics) (25.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->sdmetrics) (1.5.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->sdmetrics) (3.6.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->sdmetrics) (1.17.0)\nDownloading sdmetrics-0.21.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading copulas-0.12.2-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: copulas, sdmetrics\nSuccessfully installed copulas-0.12.2 sdmetrics-0.21.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# !unrar x data.rar","metadata":{"execution":{"iopub.status.busy":"2025-06-03T10:42:52.139782Z","iopub.execute_input":"2025-06-03T10:42:52.140199Z","iopub.status.idle":"2025-06-03T10:42:52.144334Z","shell.execute_reply.started":"2025-06-03T10:42:52.140171Z","shell.execute_reply":"2025-06-03T10:42:52.143687Z"},"id":"qQ_xbhiocHjZ","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58fdd343-c13c-49dc-8e8f-e11339b4043f"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport random\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom hyperopt import fmin, tpe, hp, Trials, STATUS_OK\nfrom hyperopt import space_eval\nfrom synthcity.plugins import Plugins\nfrom synthcity.plugins.generic.plugin_ddpm import TabDDPMPlugin as DDPM\n#from sdv.metadata import SingleTableMetadata\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport tqdm\nfrom sklearn.metrics import f1_score, r2_score\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom sdmetrics.reports.single_table import QualityReport\n#from sdmetrics.metadata import SingleTableMetadata\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.684869Z","iopub.execute_input":"2025-06-03T11:19:54.685222Z","iopub.status.idle":"2025-06-03T11:19:54.691988Z","shell.execute_reply.started":"2025-06-03T11:19:54.685198Z","shell.execute_reply":"2025-06-03T11:19:54.691003Z"},"id":"xoQSvMHY8sJ_","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"807d3e6a-f0b5-49b6-9444-718db7091da1"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"dir_datasets = '/kaggle/input/nir-sem02-moons/data/'\n\n# Загрузка реальных датасетов\nreal_data_1 = pd.read_csv(dir_datasets+'moons_dataset.csv')\n\n# Словарь датасетов для удобства\ndatasets = {\n    'two_moons': {\n                    \"data\": real_data_1,\n                    \"task\": \"regression\",\n                    \"target\": \"x2\",\n                    \"num_columns\":\n                    [\"x1\"],\n                    \"cat_columns\":\n                    []\n                },\n}\n\n\nfor name, data in datasets.items():\n    print(f\" Информация о датасете {name}:\")\n    print(f\" Количество строк: {data['data'].shape[0]}\")\n    print(f\" Количество колонок: {data['data'].shape[1]}\")\n    print(f\" Колонки: {list(data['data'].columns)}\")\n    print(f\" Задача: {data['task']}\")\n    print(f\" Целевая переменная: {data['target']}\")\n    print(f\" Числовые признаки: {data['num_columns']}\")\n    print()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-06-03T11:19:54.693035Z","iopub.execute_input":"2025-06-03T11:19:54.693325Z","iopub.status.idle":"2025-06-03T11:19:54.726604Z","shell.execute_reply.started":"2025-06-03T11:19:54.693308Z","shell.execute_reply":"2025-06-03T11:19:54.725924Z"},"id":"VKQZwZ93EGlS","outputId":"d8f44598-84ed-4cfd-8cbb-828cce292b84","trusted":true},"outputs":[{"name":"stdout","text":" Информация о датасете two_moons:\n Количество строк: 3000\n Количество колонок: 2\n Колонки: ['x1', 'x2']\n Задача: regression\n Целевая переменная: x2\n Числовые признаки: ['x1']\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"RANDOM_SEED = 42\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.727699Z","iopub.execute_input":"2025-06-03T11:19:54.727934Z","iopub.status.idle":"2025-06-03T11:19:54.732335Z","shell.execute_reply.started":"2025-06-03T11:19:54.727916Z","shell.execute_reply":"2025-06-03T11:19:54.731692Z"},"id":"Fdy8sdZxFT1p","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def process_data(dataset, num_columns, cat_columns, transformation_num_type='None', transformation_cat_type='None'):\n\n    df_processed = dataset.copy()\n\n    # Обработка числовых признаков\n    if transformation_num_type == 'CDF':\n        # CDF трансформация: преобразует значения в их эмпирическую функцию распределения\n        for col in num_columns:\n            # Правильная формула для эмпирической CDF\n            df_processed[col] = (df_processed[col].rank(method='average') - 0.5) / len(df_processed)\n\n    elif transformation_num_type == 'PLE_CDF':\n        # PLE_CDF (Probability Logit Envelope CDF) - более сложная трансформация\n        for col in num_columns:\n            # Сначала применяем CDF\n            cdf_values = (df_processed[col].rank(method='average') - 0.5) / len(df_processed)\n\n            # Затем применяем logit трансформацию с небольшим сглаживанием\n            # Избегаем 0 и 1 для предотвращения бесконечности в logit\n            epsilon = 1e-6\n            cdf_values = np.clip(cdf_values, epsilon, 1 - epsilon)\n\n            # Логит трансформация: ln(p/(1-p))\n            df_processed[col] = np.log(cdf_values / (1 - cdf_values))\n\n    # Обработка категориальных признаков\n    if transformation_cat_type == 'OHE':\n        # One Hot Encoding для категориальных признаков\n        for col in cat_columns:\n            # Создаем dummy переменные с префиксом имени колонки\n            dummy_df = pd.get_dummies(df_processed[col], prefix=col, dtype=int)\n\n            # Удаляем исходную категориальную колонку\n            df_processed = df_processed.drop(columns=[col])\n\n            # Добавляем новые dummy колонки\n            df_processed = pd.concat([df_processed, dummy_df], axis=1)\n\n    return df_processed","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.733222Z","iopub.execute_input":"2025-06-03T11:19:54.733580Z","iopub.status.idle":"2025-06-03T11:19:54.755354Z","shell.execute_reply.started":"2025-06-03T11:19:54.733554Z","shell.execute_reply":"2025-06-03T11:19:54.754627Z"},"id":"NonvG7oNFVXd","trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Определение пространства поиска гиперпараметров для DDPM\nddpm_space = {\n    'batch_size': hp.choice('batch_size', [256, 4096]),\n    'lr': hp.qloguniform('lr', np.log(1e-4), np.log(1e-3), 1e-5),\n    'num_timesteps': hp.choice('num_timesteps', [1000]),\n    'n_layers_hidden': hp.choice('n_layers_hidden', [2, 4, 6, 8]),\n    'n_units_hidden': hp.choice('n_units_hidden', [128, 256, 512, 1024]),\n    'n_iter': hp.choice('n_iter', [20000]),\n    'transformation_num_type': hp.choice('transformation_num_type', ['None']),\n    'transformation_cat_type': hp.choice('transformation_cat_type', ['None'])\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.757101Z","iopub.execute_input":"2025-06-03T11:19:54.757421Z","iopub.status.idle":"2025-06-03T11:19:54.775921Z","shell.execute_reply.started":"2025-06-03T11:19:54.757400Z","shell.execute_reply":"2025-06-03T11:19:54.775274Z"},"id":"ge6z2nc4HRii","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\n\ndef evaluate_shape(real_data, synthetic_data, cat_columns):\n    \"\"\"\n    Прямое использование метрик SDMetrics без QualityReport.\n    Для случаев, когда QualityReport не работает.\n    \"\"\"\n    # Обработка входных данных\n    if hasattr(synthetic_data, \"dataframe\"):\n        synthetic = synthetic_data.dataframe()\n    else:\n        synthetic = synthetic_data.copy()\n\n    real_data = pd.get_dummies(real_data, columns=cat_columns, drop_first=True)\n    synthetic = pd.get_dummies(synthetic, columns=cat_columns, drop_first=True)\n\n    # После get_dummies\n    real_data = real_data.astype(float)\n    synthetic = synthetic.astype(float)\n\n    # Пытаемся использовать прямые метрики\n    shape_scores = []\n\n    from sdmetrics.single_column import KSComplement\n\n    for column in real_data.select_dtypes(include=['number']).columns:\n        if column in synthetic.columns:\n            ks_score = KSComplement.compute(\n                real_data=real_data[column],\n                synthetic_data=synthetic[column]\n            )\n            shape_scores.append(ks_score)\n\n    return sum(shape_scores) / len(shape_scores) if shape_scores else 0.0","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.788003Z","iopub.execute_input":"2025-06-03T11:19:54.788573Z","iopub.status.idle":"2025-06-03T11:19:54.798799Z","shell.execute_reply.started":"2025-06-03T11:19:54.788548Z","shell.execute_reply":"2025-06-03T11:19:54.798155Z"},"id":"n-9yfPplIRvC","trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import sys\nimport os\nimport builtins\nimport contextlib\n\n@contextlib.contextmanager\ndef suppress_all_output():\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        old_stderr = sys.stderr\n        old_print = builtins.print\n        builtins.print = lambda *args, **kwargs: None\n        sys.stdout = devnull\n        sys.stderr = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr\n            builtins.print = old_print","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.800372Z","iopub.execute_input":"2025-06-03T11:19:54.800847Z","iopub.status.idle":"2025-06-03T11:19:54.818290Z","shell.execute_reply.started":"2025-06-03T11:19:54.800823Z","shell.execute_reply":"2025-06-03T11:19:54.817520Z"},"id":"tU79Ih1dOWMM","trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef generate_and_evaluate_shape_scores(params, dataset_info, n_splits=3):\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n\n    data = process_data(dataset_info['data'], dataset_info['num_columns'], params['transformation_num_type'])\n\n    kf = KFold(n_splits=n_splits, shuffle=False)\n    shape_scores = []\n\n    for train_index, test_index in kf.split(data):\n        train_data = data.iloc[train_index].reset_index(drop=True)\n        test_data = data.iloc[test_index].reset_index(drop=True)\n\n        # Создание и обучение DDPM с заданными параметрами\n        ddpm = DDPM(\n            lr=params['lr'],\n            num_timesteps=params['num_timesteps'],\n            model_params = dict(n_layers_hidden=params['n_layers_hidden'],\n                                n_units_hidden=params['n_units_hidden'],\n                                dropout=0.0),\n            #n_iter=params['n_iter'],\n            batch_size=params['batch_size']\n        )\n\n        # Обучение модели на реальных данных\n        with suppress_all_output():\n            ddpm.fit(train_data)\n\n        # Генерация синтетических данных\n        synthetic_data = ddpm.generate(len(train_data))\n\n        # Вычисляем Shape-score\n        score = evaluate_shape(\n            test_data,\n            synthetic_data,\n        dataset_info[\"cat_columns\"])\n\n        shape_scores.append(score)\n\n    return np.mean(shape_scores)","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.819124Z","iopub.execute_input":"2025-06-03T11:19:54.819411Z","iopub.status.idle":"2025-06-03T11:19:54.842060Z","shell.execute_reply.started":"2025-06-03T11:19:54.819378Z","shell.execute_reply":"2025-06-03T11:19:54.841327Z"},"id":"YR4_7KpJI0wX","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def optimize_dataset(dataset_name, dataset_info, max_evals=30):\n    print(f\"Оптимизация для датасета: {dataset_name}\")\n\n    # Создаем объект для хранения истории поиска\n    trials = Trials()\n\n    # Определяем целевую функцию для оптимизации\n    def objective(params):\n        print(\"=\"*50)\n        shape_score = generate_and_evaluate_shape_scores(params, dataset_info)\n\n        print(f\"Shape-score: {shape_score}\")\n        print(params)\n        print(\"=\"*50)\n\n        # Для Shape-score мы хотим максимизировать метрику, поэтому возвращаем отрицательное значение\n        return {\n            'loss': -shape_score,  # отрицательное для максимизации\n            'status': STATUS_OK,\n            'shape_score': shape_score\n        }\n\n    # Запускаем оптимизацию с помощью TPE алгоритма\n    rng = np.random.default_rng(42)  # Используем фиксированный seed\n    best = fmin(\n        fn=objective,\n        space=ddpm_space,\n        algo=tpe.suggest,\n        max_evals=max_evals,\n        trials=trials,\n        rstate=rng\n    )\n\n    # Автоматическое декодирование параметров\n    best_params = space_eval(ddpm_space, best)\n\n    # Находим лучший результат\n    best_trial = min(trials.trials, key=lambda x: x['result']['loss'])\n    best_shape_score = best_trial['result'].get('shape_score', None)\n\n    results = {\n        'best_params': best_params,\n        'best_shape_score': best_shape_score,\n        'shape_score_diff_from_optimal': -best_trial['result']['loss']  # убираем минус для читаемости\n    }\n\n    print(f\"Лучший Shape-score для {dataset_name}: {best_shape_score}\")\n    print(f\"Лучшие параметры: {best_params}\")\n    print('-' * 50)\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-06-03T11:19:54.842871Z","iopub.execute_input":"2025-06-03T11:19:54.843134Z","iopub.status.idle":"2025-06-03T11:19:54.864306Z","shell.execute_reply.started":"2025-06-03T11:19:54.843093Z","shell.execute_reply":"2025-06-03T11:19:54.863439Z"},"id":"vD2xqTjyNSG5","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Словарь для хранения результатов\nall_results = {}\n\n# Указываем количество итераций для каждого датасета\nmax_evals = 100\n\n# Запускаем оптимизацию для каждого датасета\nfor dataset_name in datasets:\n    data = datasets[dataset_name]\n    all_results[dataset_name] = optimize_dataset(dataset_name, data, max_evals)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-06-03T11:19:54.866068Z","iopub.execute_input":"2025-06-03T11:19:54.866316Z","iopub.status.idle":"2025-06-03T14:59:35.068309Z","shell.execute_reply.started":"2025-06-03T11:19:54.866300Z","shell.execute_reply":"2025-06-03T14:59:35.067724Z"},"id":"7ZmVmaNlNaVG","outputId":"ea41c488-87c8-47bf-8f6b-780cbc0f10a5","trusted":true},"outputs":[{"name":"stdout","text":"Оптимизация для датасета: two_moons\n==================================================     \nShape-score: 0.9609166666666668                        \n{'batch_size': 256, 'lr': 0.00042, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================     \n==================================================                                   \nShape-score: 0.9589166666666666                                                      \n{'batch_size': 4096, 'lr': 0.00041000000000000005, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9605833333333335                                                      \n{'batch_size': 256, 'lr': 0.00012000000000000002, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9605                                                                  \n{'batch_size': 4096, 'lr': 0.00016, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9603333333333334                                                      \n{'batch_size': 256, 'lr': 0.00012000000000000002, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9651666666666667                                                      \n{'batch_size': 4096, 'lr': 0.00014000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9635000000000001                                                      \n{'batch_size': 256, 'lr': 0.00099, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9615833333333333                                                      \n{'batch_size': 256, 'lr': 0.00068, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9625                                                                  \n{'batch_size': 256, 'lr': 0.00059, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                   \nShape-score: 0.9595833333333333                                                      \n{'batch_size': 4096, 'lr': 0.00030000000000000003, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                   \n==================================================                                    \nShape-score: 0.9522499999999999                                                       \n{'batch_size': 4096, 'lr': 0.00011, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9605833333333332                                                       \n{'batch_size': 4096, 'lr': 0.00041000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9633333333333333                                                       \n{'batch_size': 256, 'lr': 0.00054, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9589166666666666                                                       \n{'batch_size': 4096, 'lr': 0.00029, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9636666666666667                                                       \n{'batch_size': 256, 'lr': 0.0008, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9623333333333334                                                       \n{'batch_size': 256, 'lr': 0.00097, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9630000000000001                                                       \n{'batch_size': 256, 'lr': 0.0006500000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9586666666666667                                                       \n{'batch_size': 4096, 'lr': 0.00013000000000000002, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9628333333333333                                                       \n{'batch_size': 256, 'lr': 0.00071, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.96225                                                                  \n{'batch_size': 4096, 'lr': 0.0005200000000000001, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.96525                                                                  \n{'batch_size': 4096, 'lr': 0.00021, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9645                                                        \n{'batch_size': 4096, 'lr': 0.0002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9649166666666668                                            \n{'batch_size': 4096, 'lr': 0.00023, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9642499999999999                                            \n{'batch_size': 4096, 'lr': 0.00016, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9644166666666667                                            \n{'batch_size': 4096, 'lr': 0.00024000000000000003, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9642499999999999                                            \n{'batch_size': 4096, 'lr': 0.00016, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9599166666666666                                              \n{'batch_size': 4096, 'lr': 0.00019, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9650833333333333                                              \n{'batch_size': 4096, 'lr': 0.00025, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9643333333333333                                              \n{'batch_size': 4096, 'lr': 0.00035000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9633333333333333                                              \n{'batch_size': 4096, 'lr': 0.00019, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9646666666666667                                              \n{'batch_size': 4096, 'lr': 0.00015000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9634166666666667                                              \n{'batch_size': 4096, 'lr': 0.0001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9590000000000001                                              \n{'batch_size': 4096, 'lr': 0.00014000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9625                                                          \n{'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9645                                                          \n{'batch_size': 4096, 'lr': 0.00011, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9578333333333333                                              \n{'batch_size': 4096, 'lr': 0.00033000000000000005, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9602499999999999                                              \n{'batch_size': 4096, 'lr': 0.00027, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9604166666666666                                              \n{'batch_size': 4096, 'lr': 0.00019, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9624166666666666                                              \n{'batch_size': 4096, 'lr': 0.00012000000000000002, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9600833333333334                                              \n{'batch_size': 256, 'lr': 0.00038, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9643333333333333                                              \n{'batch_size': 4096, 'lr': 0.0001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9600833333333334                                              \n{'batch_size': 4096, 'lr': 0.00046, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9625                                                          \n{'batch_size': 256, 'lr': 0.00017, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9512499999999999                                              \n{'batch_size': 4096, 'lr': 0.00014000000000000001, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9575833333333333                                              \n{'batch_size': 4096, 'lr': 0.00026000000000000003, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9630000000000001                                              \n{'batch_size': 256, 'lr': 0.00029, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9603333333333334                                              \n{'batch_size': 4096, 'lr': 0.00021, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.96225                                                         \n{'batch_size': 256, 'lr': 0.00017, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.964                                                           \n{'batch_size': 4096, 'lr': 0.00011, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9471666666666666                                              \n{'batch_size': 4096, 'lr': 0.00012000000000000002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9638333333333332                                              \n{'batch_size': 256, 'lr': 0.00045000000000000004, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9599166666666666                                              \n{'batch_size': 4096, 'lr': 0.00031, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9512499999999999                                              \n{'batch_size': 4096, 'lr': 0.00013000000000000002, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9620833333333333                                              \n{'batch_size': 256, 'lr': 0.00037000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9643333333333333                                              \n{'batch_size': 4096, 'lr': 0.00018, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9579999999999999                                              \n{'batch_size': 4096, 'lr': 0.00027, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.96175                                                         \n{'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9635833333333332                                              \n{'batch_size': 256, 'lr': 0.0008600000000000001, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9646666666666667                                              \n{'batch_size': 4096, 'lr': 0.00015000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9644166666666667                                              \n{'batch_size': 4096, 'lr': 0.00024000000000000003, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9619166666666668                                              \n{'batch_size': 4096, 'lr': 0.00054, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.96325                                                         \n{'batch_size': 256, 'lr': 0.0006000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9485833333333334                                              \n{'batch_size': 4096, 'lr': 0.00013000000000000002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9605833333333335                                              \n{'batch_size': 4096, 'lr': 0.00033000000000000005, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9581666666666667                                              \n{'batch_size': 4096, 'lr': 0.00021, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9644166666666667                                              \n{'batch_size': 4096, 'lr': 0.00024000000000000003, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9638333333333334                                              \n{'batch_size': 4096, 'lr': 0.00026000000000000003, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9651666666666666                                              \n{'batch_size': 4096, 'lr': 0.00017, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9651666666666667                                              \n{'batch_size': 4096, 'lr': 0.00015000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.964                                                           \n{'batch_size': 4096, 'lr': 0.00011, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                           \n==================================================                           \nShape-score: 0.9651666666666667                                            \n{'batch_size': 4096, 'lr': 0.00015000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9651666666666667                                            \n{'batch_size': 4096, 'lr': 0.00015000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9651666666666667                                            \n{'batch_size': 4096, 'lr': 0.00014000000000000001, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9645                                                        \n{'batch_size': 4096, 'lr': 0.0002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.96075                                                       \n{'batch_size': 4096, 'lr': 0.0001, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9576666666666668                                            \n{'batch_size': 4096, 'lr': 0.00018, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9646666666666667                                            \n{'batch_size': 4096, 'lr': 0.00013000000000000002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9471666666666666                                            \n{'batch_size': 4096, 'lr': 0.00012000000000000002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9627500000000001                                            \n{'batch_size': 256, 'lr': 0.00016, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9578333333333333                                            \n{'batch_size': 4096, 'lr': 0.00018, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.96525                                                       \n{'batch_size': 4096, 'lr': 0.00028000000000000003, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9636666666666667                                            \n{'batch_size': 4096, 'lr': 0.00029, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9631666666666666                                            \n{'batch_size': 4096, 'lr': 0.00043000000000000004, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9631666666666666                                            \n{'batch_size': 4096, 'lr': 0.00037000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9615                                                        \n{'batch_size': 256, 'lr': 0.00032, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.96175                                                       \n{'batch_size': 4096, 'lr': 0.00023, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.96125                                                       \n{'batch_size': 4096, 'lr': 0.00027, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.95775                                                       \n{'batch_size': 4096, 'lr': 0.0004900000000000001, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.963                                                         \n{'batch_size': 256, 'lr': 0.0004, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                         \nShape-score: 0.9653333333333333                                            \n{'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                         \n==================================================                                    \nShape-score: 0.9643333333333333                                                       \n{'batch_size': 4096, 'lr': 0.00035000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9536666666666666                                                       \n{'batch_size': 4096, 'lr': 0.0002, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.96075                                                                  \n{'batch_size': 4096, 'lr': 0.00030000000000000003, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9630833333333332                                                       \n{'batch_size': 256, 'lr': 0.00028000000000000003, 'n_iter': 20000, 'n_layers_hidden': 2, 'n_units_hidden': 1024, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9643333333333333                                                       \n{'batch_size': 4096, 'lr': 0.00035000000000000005, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9618333333333333                                                       \n{'batch_size': 4096, 'lr': 0.00025, 'n_iter': 20000, 'n_layers_hidden': 6, 'n_units_hidden': 256, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9653333333333333                                                       \n{'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.9600833333333334                                                       \n{'batch_size': 256, 'lr': 0.00023, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 128, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.96175                                                                  \n{'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 4, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n==================================================                                    \nShape-score: 0.96525                                                                  \n{'batch_size': 4096, 'lr': 0.00021, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n==================================================                                    \n100%|██████████| 100/100 [3:39:40<00:00, 131.80s/trial, best loss: -0.9653333333333333]\nЛучший Shape-score для two_moons: 0.9653333333333333\nЛучшие параметры: {'batch_size': 4096, 'lr': 0.00022, 'n_iter': 20000, 'n_layers_hidden': 8, 'n_units_hidden': 512, 'num_timesteps': 1000, 'transformation_cat_type': 'None', 'transformation_num_type': 'None'}\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"for dataset_name in datasets:\n    print(dataset_name, all_results[dataset_name]['best_shape_score'])","metadata":{"execution":{"iopub.status.busy":"2025-06-03T14:59:35.068968Z","iopub.execute_input":"2025-06-03T14:59:35.069208Z","iopub.status.idle":"2025-06-03T14:59:35.074177Z","shell.execute_reply.started":"2025-06-03T14:59:35.069182Z","shell.execute_reply":"2025-06-03T14:59:35.073321Z"},"id":"-VGL5IBfVYnK","trusted":true},"outputs":[{"name":"stdout","text":"two_moons 0.9653333333333333\n","output_type":"stream"}],"execution_count":29}]}